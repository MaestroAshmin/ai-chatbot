{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad_v2 (/home/phung/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3615becd72c7452fb4593996e7bc244f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import csv\n",
    "\n",
    "squad_dataset = load_dataset('squad_v2')\n",
    "# Get context and question from dataset\n",
    "squad_contexts = [x['context'] for x in squad_dataset['train']] + [x['context'] for x in squad_dataset['validation']]\n",
    "squad_questions = [x['question'] for x in squad_dataset['train']] + [x['question'] for x in squad_dataset['validation']]\n",
    "\n",
    "with open('questions_answers_swinburne_monash.csv') as csv_file:\n",
    "    with open('out-of-scope-dataset.csv', 'w', newline='') as new_csv_file:\n",
    "        fieldnames = ['statement', 'label']\n",
    "        writer = csv.DictWriter(new_csv_file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        # 0 for in-scope, 1 for out-of-scope\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for row in reader:\n",
    "            question = row['question']\n",
    "            answer = row['answer']\n",
    "            label = 0\n",
    "            writer.writerow({'statement': question, 'label': 0})\n",
    "            writer.writerow({'statement': answer, 'label': 1})\n",
    "        for question in squad_questions:\n",
    "            label = 1\n",
    "            writer.writerow({'statement': question, 'label': label})\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T18:28:15.188334590Z",
     "start_time": "2023-05-12T18:27:50.995954034Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/phung/.cache/huggingface/datasets/csv/default-0ba080e82ee130e3/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased', cache_dir=\"/mnt/external-ssd/cache_dir\")\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "faq_dataset = Dataset.from_csv('out-of-scope-dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T21:37:55.773415487Z",
     "start_time": "2023-05-12T21:37:51.786194159Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/144748 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cbaf71edc2a44fdbb0c5768e2bdf7b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def tokenize_faq(data):\n",
    "    word = \"Swinburne\"\n",
    "    sentences = data[\"statement\"]\n",
    "    # Get the index of the word in each sentence (if it exists)\n",
    "    word_idxs_in_sent = []\n",
    "    for sent in sentences:\n",
    "        try:\n",
    "            idx = sent.split(\" \").index(word)\n",
    "        except ValueError:\n",
    "            # Word not found in sentence\n",
    "            idx = -1\n",
    "        word_idxs_in_sent.append(idx)\n",
    "    # Index of word in the sentences (word-tokenized!)\n",
    "    word_idxs_in_sent = [idx if idx != -1 else None for idx in word_idxs_in_sent]\n",
    "    encoded = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # For each sentence, set a subword token to False if it belongs to the word (becomes 0 in LongTensor)\n",
    "    # match_idxs = torch.LongTensor([[wid != word_idxs_in_sent[batch_idx] for wid in encoded.word_ids(batch_idx)]\n",
    "                  # for batch_idx in range(len(sentences))])\n",
    "    attention_mask = encoded[\"attention_mask\"]\n",
    "    # Build a custom mask that zeroes out the subword tokens corresponding to the word\n",
    "    custom_mask = torch.LongTensor([[wid != idx if idx is not None else True for wid in encoded.word_ids(batch_idx)]\n",
    "                  for batch_idx, idx in enumerate(word_idxs_in_sent)])\n",
    "\n",
    "    # Merge the custom mask with the original attention mask\n",
    "    encoded[\"attention_mask\"] = torch.where(custom_mask == 0, custom_mask, attention_mask)\n",
    "\n",
    "    # print(\"Original mask\", attention_mask)\n",
    "    # print(\"Custom mask\", custom_mask)\n",
    "    # print(\"Merged mask\", encoded[\"attention_mask\"])\n",
    "\n",
    "    # Merge: if a word is zero in our custom match, merge, if not, use the original mask\n",
    "    # This ensures that we mask the word IDs but keep the original mask for special tokens (cls, pad, etc.)\n",
    "    # encoded[\"attention_mask\"] = torch.where(match_idxs == 0, match_idxs, encoded[\"attention_mask\"])\n",
    "    if tokenizer.is_fast:\n",
    "        encoded[\"word_ids\"] = [encoded.word_ids(i) for i in range(len(encoded[\"input_ids\"]))]\n",
    "    return encoded\n",
    "\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_faq_dataset = faq_dataset.map(tokenize_faq, batched=True)\n",
    "tokenized_faq_dataset_without_statements = tokenized_faq_dataset.remove_columns(\"statement\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T18:31:03.278750409Z",
     "start_time": "2023-05-12T18:30:54.273421362Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'input_ids', 'attention_mask', 'word_ids'],\n",
      "        num_rows: 130273\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'input_ids', 'attention_mask', 'word_ids'],\n",
      "        num_rows: 14475\n",
      "    })\n",
      "})\n",
      "{'statement': 'What support can I expect?', 'label': 0, 'input_ids': [101, 2054, 2490, 2064, 1045, 5987, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'word_ids': [None, 0, 1, 2, 3, 4, 5, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]}\n",
      "{'statement': 'As a Swinburne Online student, youâ€™ll have support for extended hours, seven days a week, with Student Advisors available to help with anything from tech support to research advice and dedicated online tutors in each of your units. Learn more about your support .', 'label': 1, 'input_ids': [101, 2004, 1037, 25430, 2378, 8022, 2063, 3784, 3076, 1010, 2017, 1521, 2222, 2031, 2490, 2005, 3668, 2847, 1010, 2698, 2420, 1037, 2733, 1010, 2007, 3076, 18934, 2800, 2000, 2393, 2007, 2505, 2013, 6627, 2490, 2000, 2470, 6040, 1998, 4056, 3784, 14924, 2015, 1999, 2169, 1997, 2115, 3197, 1012, 4553, 2062, 2055, 2115, 2490, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'word_ids': [None, 0, 1, 2, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]}\n"
     ]
    }
   ],
   "source": [
    "split_dataset = tokenized_faq_dataset_without_statements.train_test_split(test_size=0.1)\n",
    "print(split_dataset)\n",
    "print(tokenized_faq_dataset[0])\n",
    "print(tokenized_faq_dataset[1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T18:31:35.701266449Z",
     "start_time": "2023-05-12T18:31:35.640792538Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "id2label = {0: \"in-scope\", 1: \"out-of-scope\"}\n",
    "\n",
    "label2id = {\"in-scope\": 0, \"out-of-scope\": 1}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T18:31:47.153972921Z",
     "start_time": "2023-05-12T18:31:47.141863063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "\n",
    "chunk_size = 128\n",
    "\n",
    "\n",
    "# def group_texts(data):\n",
    "#     concatenated_examples = {k: sum(data[k], []) for k in data.keys()}\n",
    "#     total_length = len(concatenated_examples[list(data.keys())[0]])\n",
    "#     total_length = (total_length // chunk_size) * chunk_size\n",
    "#     result = {\n",
    "#         k: [t[i: i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "#         for k, t in concatenated_examples.items()\n",
    "#     }\n",
    "#     result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "#     return result\n",
    "#\n",
    "#\n",
    "# lm_datasets = tokenized_faq_dataset.map(group_texts, batched=True)\n",
    "# split_dataset = tokenized_faq_dataset.train_test_split(test_size=0.1)\n",
    "# print(split_dataset)\n",
    "\n",
    "distilbert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ").to('cuda')\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Training hyperparameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/mnt/external-ssd/Projects/models/faq_distilbert\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_total_limit=10,\n",
    "    learning_rate=2e-5,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=distilbert_model,\n",
    "    args=training_args,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "# train using torch mps device\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"glue\", \"mrpc\", cache_dir=\"/mnt/external-ssd/cache_dir\")\n",
    "metric.compute(predictions=trainer.predict(split_dataset[\"test\"]).predictions, references=split_dataset[\"test\"][\"labels\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'in-scope', 'score': 0.999913215637207}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, pipeline\n",
    "# my_model = AutoModelForSequenceClassification.from_pretrained('/Volumes/PortableSSD/Projects/models/faqs_distilbert_classifier/checkpoint-161000', num_labels=2)\n",
    "\n",
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "# outputs = my_model(**inputs)\n",
    "\n",
    "# tokenizer.decode(outputs)\n",
    "my_pipline = pipeline('text-classification', model='/mnt/external-ssd/Projects/models/faq_distilbert/checkpoint-40500', tokenizer=tokenizer)\n",
    "print(my_pipline('Swinburne'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-12T21:38:17.881634006Z",
     "start_time": "2023-05-12T21:38:17.011216849Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
